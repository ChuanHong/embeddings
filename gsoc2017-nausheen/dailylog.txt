
*****************************************************************************
Daily logs for GSoC 2017
*****************************************************************************

Dropbox link for Experiments Excel sheet and screenshots: 
https://www.dropbox.com/sh/4180ka27eydm5rk/AADU54wB3ofU2N3KBELm3bhYa?dl=0

=============================================================================
30th May to 15th June 2017:
=============================================================================
Ran opensource codes for 
i) TransE
ii) HolE
iii) ComplEx

Pending Issues to fix:
i) HolE input format for FB15K

=============================================================================
16th June 2017:
=============================================================================
Done :
i)  DistMult executed for WN18 and FB15K
Results noted.

=============================================================================
19th June 2017 :
=============================================================================
To Do:
Run SSP model.

What I did :
* Tried to run SSP code on Linux Machine, some errors during runtime.
* SSP documentations says the authors used Intel C++ Compiler on Visual Studio.


=============================================================================
20th June 2017:
=============================================================================
What I did :
* Set up Visual studio and Intel C++ on a Windows machine.
* Had weekly hangout discussion with the mentors and decided to document and 
figure out :
    1) time complexity 
    2) space complexity/requirements 
for various models. 

=============================================================================
21st June 2017 to 24th June 2017:
=============================================================================
Tried to make SSP run on Linux and Windows. 
Unfortunately, it did not execute.

=============================================================================
25th June 2017 :
=============================================================================

1)  When I check the experiments table, the results of HoLE and ComplEx looks too similar.
So to gain some more insight, I edited the HoLE code to give Hits@1, Hits@3 and 
Hits@10 information.

The original code gave only Hits@10 values.

Ran the code and got resuts.

2) The HolE github code did not have the FB15K bin file dataset. I created the bin file for FB15K
from the benchmark FB15K dataset, and put the code for execution. The bin file was the required 
input format for running the code.

wrote : data2bin.py

3) Have put the HolE code running for the FB15K dataset from 2) 

==============================================================================
26th June 2017 :
==============================================================================

*   Wrote Week 4 article.
*   Hangout meet with Tomasso

==============================================================================
4th July 2017 :
==============================================================================
* Wrote Code for DBpedia to Freebase mapping

To do:
* Run code on DBpedia
* Weekly Meeting
    -Decided to test on subsets with and without dbp, and rdf:type like predicates

==============================================================================
9th July :
==============================================================================
*Compared the performance of complex code CPU vs GPU.
*Put a dbpedia subset to run for Transe and complex.

==============================================================================
10th July:
==============================================================================
*Weekly meeting
Minutes of meetings

short summary:
- experiments showed excellent results (99.6%) using DistMult on the DBpedia special subset (see blog post);
- now, we need to focus on understanding which algorithm is best suited for DBpedia with respect to accuracy & runtime, given the dataset structure;
- we will need DBpedia subsets having different structure (e.g., with/without literals, types, _property_ namespaces);
- for a determined set (maybe the best performing one?), create subsets having different sizes and plot their runtime on chart, so we can see which one scales better.

==============================================================================
10th July till 19th July:
==============================================================================
*created the new folder createDBpediaDataset
* Wrote code to find different subsets for DBpedia as mentioned in the previous meetings MOM
* put codes for the following combinations:
    SET0 (dbpedia mapped dataset (with type,subject,literals,wikilinks,assame as predicates)) : Found that Codes do NOT run with literals kind of data
    SET1 (SET0 - (literals,type,subject,wikilinks,assame as predicates)) : Results noted
    SET2 (SET0 - (literals)) 
    
    
==============================================================================
19th July till 22th July:
==============================================================================
*Unavailable due to academic reasons

===============================================================================
23rd July :
===============================================================================
* tried codes on SET1 

===============================================================================
1st August :
===============================================================================
*Hyperparameter tuning of DistMult and Complex on Set3
===============================================================================
2nd August :
===============================================================================
*Hyperparameter tuning of TransE on Set3

